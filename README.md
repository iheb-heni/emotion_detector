# ğŸ§  Emotion Detector â€” CNN + Flask + Next.js

## ğŸ“˜ Description du projet
**Emotion Detector** est une application web complÃ¨te qui utilise un **modÃ¨le de Deep Learning (CNN)** pour analyser une image de visage et prÃ©dire lâ€™Ã©motion dâ€™une personne en temps rÃ©el via la webcam.

Ce projet combine :
- ğŸ§© **IA / Deep Learning** (TensorFlow + CNN)
- âš™ï¸ **Backend API Flask**
- ğŸ¨ **Frontend Next.js + Tailwind CSS**
- ğŸ“¸ **Webcam en direct** pour la dÃ©tection des Ã©motions

---

## ğŸ§  Partie 1 â€” Le ModÃ¨le IA (CNN)

### ğŸ” Objectif
Le modÃ¨le de deep learning est entraÃ®nÃ© pour reconnaÃ®tre 7 Ã©motions humaines de base Ã  partir dâ€™images de visages :
- ğŸ˜„ **Happy**
- ğŸ˜¢ **Sad**
- ğŸ˜¡ **Angry**
- ğŸ˜¨ **Fear**
- ğŸ˜² **Surprise**
- ğŸ˜ **Neutral**
- ğŸ¤¢ **Disgust**

---

### ğŸ§¾ Dataset utilisÃ© â€” FER2013

- **Nom :** [FER2013 Facial Expression Recognition Dataset](https://www.kaggle.com/datasets/msambare/fer2013)
- **Taille :** Environ 35,000 images en niveaux de gris (48x48 pixels)
- **Structure :**
  ```
  fer2013/
  â”œâ”€â”€ train/
  â”‚   â”œâ”€â”€ angry/
  â”‚   â”œâ”€â”€ disgust/
  â”‚   â”œâ”€â”€ fear/
  â”‚   â”œâ”€â”€ happy/
  â”‚   â”œâ”€â”€ neutral/
  â”‚   â”œâ”€â”€ sad/
  â”‚   â””â”€â”€ surprise/
  â””â”€â”€ test/
      â”œâ”€â”€ angry/
      â”œâ”€â”€ disgust/
      â”œâ”€â”€ ...
  ```
- **Format :** chaque image reprÃ©sente un visage exprimant une Ã©motion.

---

### ğŸ§® Architecture du ModÃ¨le CNN

Le modÃ¨le est basÃ© sur un **rÃ©seau de neurones convolutifs** (CNN) simple mais efficace pour la classification dâ€™images.

```python
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),
    MaxPooling2D(2,2),
    
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(7, activation='softmax')
])
```

- **Optimiseur :** Adam  
- **Fonction de perte :** Categorical Crossentropy  
- **MÃ©trique :** Accuracy  
- **Ã‰poques :** 25 (environ)  
- **Batch size :** 64  

Le modÃ¨le est ensuite sauvegardÃ© :
```python
model.save("/kaggle/working/emotion_detector_model.h5")
```

---

### ğŸ“Š RÃ©sultats

| MÃ©trique        | Valeur Approx. |
|-----------------|----------------|
| Accuracy Train  | ~85%            |
| Accuracy Test   | ~75%            |

---

## ğŸ§± Partie 2 â€” Backend Flask

### ğŸ“ Structure du backend

```
emotion_detector/
â”‚
â”œâ”€â”€ back/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ emotion_detector_model.h5
â”‚
â””â”€â”€ front/
    â””â”€â”€ (Next.js project)
```

---

### ğŸ“œ `requirements.txt`

```txt
flask
flask-cors
tensorflow==2.20.0
pillow
numpy
```

### â–¶ï¸ ExÃ©cution du serveur

```bash
cd back
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python app.py
```

Serveur accessible sur :
```
http://127.0.0.1:5000/predict
```

---

## ğŸ’» Partie 3 â€” Frontend Next.js + Tailwind + Webcam

### âš™ï¸ Initialisation du projet

```bash
npx create-next-app@latest front
cd front
npm install react-webcam axios


### â–¶ï¸ Lancer le frontend

```bash
cd front
npm run dev
```

Lâ€™application est disponible sur :
```
http://localhost:3000
```

â¡ï¸ Clique sur **"Detect Emotion"** pour capturer une image et voir ton Ã©motion prÃ©dite en temps rÃ©el.

---

## ğŸ§© Workflow global

```mermaid
graph LR
A[Webcam - Next.js] -->|Capture image| B[API Flask /predict]
B -->|JSON Response| A
B -->|Charge modÃ¨le CNN| C[TensorFlow]
C -->|PrÃ©diction| B
```

---

## ğŸ“¦ AmÃ©liorations possibles

- ğŸ¥ DÃ©tection automatique via **OpenCV** (visage + Ã©motion)
- ğŸ’¾ Sauvegarde des prÃ©dictions dans une base de donnÃ©es
- ğŸš€ DÃ©ploiement du modÃ¨le sur **Render / Vercel / HuggingFace Spaces**
- ğŸ“ˆ Interface utilisateur plus avancÃ©e (historique des Ã©motions)

---

## ğŸ‘¨â€ğŸ’» Auteur

**Heni Iheb**  
Full-Stack Web Developer & AI Enthusiast  
ğŸ“§ Contact : [LinkedIn](#) | [Portfolio](#)

---

## ğŸ§¾ Licence

Ce projet est open-source sous licence **MIT**.
